# * For documentation of the values have a look at [bjw-s-labs common helm chart](https://github.com/bjw-s-labs/helm-charts/blob/main/charts/library/common/values.yaml)

### USER SECTION START ###
# ! change the following value
# * use `pwgen -s 40 1` to generate `DB_PASSWORD`
DB_PASSWORD: "super-secret-password"

# ! change the following value
DOMAIN: paperless.local
# ! change the following value
APP_URL: https://paperless.local

# ! change the following value
# * use `pwgen -s 70 1` to generate `SECRET_KEY`
SECRET_KEY: replace-with-long-secret

DB_HOSTNAME: "{{ .Release.Name }}-database-cluster-rw"
DB_NAME: "paperless"
DB_USER: "paperless"

TIME_ZONE: Europe/Berlin
OCR_LANGUAGE: deu+eng
### USER SECTION END ###

# Configuration of the main paperless deployment
paperless:
  enabled: true

  global:
    nameOverride: server

  controllers:
    main:
      type: deployment
      strategy: RollingUpdate
      replicas: 1
      containers:
        main:
          image:
            repository: ghcr.io/paperless-ngx/paperless-ngx
            tag: "2.19.6"
            pullPolicy: IfNotPresent
          env:
            PAPERLESS_URL: "{{ .Values.APP_URL }}"
            PAPERLESS_REDIS: redis://{{ .Release.Name }}:6379
            PAPERLESS_DBHOST: "{{ .Values.DB_HOSTNAME }}"
            PAPERLESS_TIKA_ENABLED: 1
            PAPERLESS_TIKA_GOTENBERG_ENDPOINT: http://{{ .Release.Name }}:3000
            PAPERLESS_TIKA_ENDPOINT: http://{{ .Release.Name }}:9998
            PAPERLESS_TIME_ZONE: "{{ .Values.TIME_ZONE }}"
            PAPERLESS_OCR_LANGUAGE: "{{ .Values.OCR_LANGUAGE }}"
            PAPERLESS_FILENAME_FORMAT: "{{ `{{ created_year }}/{{ correspondent }}/{{ title }}` }}"
            PAPERLESS_SECRET_KEY:
              valueFrom:
                secretKeyRef:
                  name: "{{ .Release.Name }}-secret-key"
                  key: SECRET_KEY
            PAPERLESS_DBNAME: "{{ .Values.DB_NAME }}"
            PAPERLESS_DBUSER: "{{ .Values.DB_USER }}"
            PAPERLESS_DBPASS:
              valueFrom:
                secretKeyRef:
                  name: "{{ .Release.Name }}-db-pass"
                  key: DB_PASS
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          # probes:
          #   liveness:
          #   readiness:
          #   startup:
          # ! set the following value as needed
          resources: {}

  secrets:
    secret-key:
      enabled: true
      stringData:
        SECRET_KEY: "{{ .Values.SECRET_KEY }}"

    db-pass:
      enabled: true
      stringData:
        DB_PASS: "{{ .Values.DB_PASSWORD }}"

  service:
    main:
      enabled: true
      controller: main
      primary: true
      type: ClusterIP
      ports:
        http:
          enabled: true
          primary: true
          port: 8000
          targetPort: http
          protocol: HTTP

  ingress:
    main:
      enabled: false
      # ! add additional proxy annotations
      # annotations:
      ### nginx.ingress.kubernetes.io/proxy-body-size: "1G"
      # sample annotations for adequate timeout values to support websockets
      ### nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
      ### nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
      # ! set `className` if not the default ingress class should be used
      # className: ingress-class-name
      hosts:
        - host: "{{ .Values.DOMAIN }}"
          paths:
            - path: "/"
              service:
                identifier: main
      tls:
        - secreetName: "{{ .Release.Name }}-cert"
          hosts:
            - "{{ .Values.DOMAIN }}"

  route:
    main:
      enabled: false
      kind: HTTPRoute
      # ! set the gateway to connect in `parentRefs`
      # parentRefs:
      #   - group: gateway.networking.k8s.io
      #     kind: Gateway
      #     name:
      #     namespace:
      #     sectionName: https
      hostnames:
        - "{{ .Values.DOMAIN }}"
      rules:
        - backendRefs:
            - identifier: main
          matches:
            - path:
                type: PathPrefix
                value: /
          # ! if you want to add filters you must override the complete rules section
          # filters:
          #   - type: ResponseHeaderModifier
          #     responseHeaderModifier:
          #       remove:
          #         - X-Powered-By
          #         - Server
          #       add:
          #         - name: X-Frame-Options
          #           value: SAMEORIGIN
          #         - name: Content-Security-Policy
          #           value: "frame-ancestors 'self';"
          #         - name: Strict-Transport-Security
          #           value: "max-age=15552001; includeSubdomains; preload"

  persistence:
    data:
      enabled: true
      type: persistentVolumeClaim
      # ! set `storageClass` if not the default storage class should be used
      # storageClass: storage-class-name
      # ! set `existingClaim` if you provide the PVC externally
      # existingClaim: "{{ .Release.Name }}-data-pvc"
      accessMode: ReadWriteOnce
      size: 2Gi
      retain: true
      advancedMounts:
        main:
          main:
            - path: /usr/src/paperless/data
              readOnly: false

    media:
      enabled: true
      type: persistentVolumeClaim
      # ! set `storageClass` if not the default storage class should be used
      # storageClass: storage-class-name
      # ! set `existingClaim` if you provide the PVC externally
      # existingClaim: "{{ .Release.Name }}-media-pvc"
      accessMode: ReadWriteOnce
      size: 2Gi
      retain: true
      advancedMounts:
        main:
          main:
            - path: /usr/src/paperless/media
              readOnly: false

    export:
      enabled: true
      type: emptyDir

    consume:
      enabled: true
      type: emptyDir

valkey:
  enabled: true

  global:
    nameOverride: valkey

  controllers:
    main:
      type: deployment
      strategy: Recreate
      replicas: 1
      containers:
        main:
          image:
            repository: valkey/valkey
            tag: "9.0-alpine"
            pullPolicy: IfNotPresent
          ports:
            - name: redis
              containerPort: 6379
              protocol: TCP
          probes:
            liveness:
              enabled: true
              custom: true
              spec:
                exec:
                  command:
                    - sh
                    - -c
                    - "valkey-cli ping | grep PONG"
                initialDelaySeconds: 30
                periodSeconds: 10
                timeoutSeconds: 5
                failureThreshold: 3
            readiness:
              enabled: true
              custom: true
              spec:
                exec:
                  command:
                    - sh
                    - -c
                    - "valkey-cli ping | grep PONG"
                initialDelaySeconds: 5
                periodSeconds: 10
                timeoutSeconds: 5
                failureThreshold: 3
            startup:
              enabled: true
              custom: true
              spec:
                exec:
                  command:
                    - sh
                    - -c
                    - "valkey-cli ping | grep PONG"
                initialDelaySeconds: 0
                periodSeconds: 10
                timeoutSeconds: 5
                failureThreshold: 30
          # ! set the following value as needed
          resources: {}

  service:
    main:
      enabled: true
      controller: main
      primary: true
      type: ClusterIP
      ports:
        redis:
          enabled: true
          primary: true
          port: 6379
          targetPort: redis
          protocol: TCP
        http:
          enabled: false

  persistence:
    data:
      enabled: true
      size: 1Gi
      # Optional: Set this to persistentVolumeClaim to keep redis data persistent
      type: emptyDir
      accessMode: ReadWriteOnce
      # ! set `storageClass` if not the default provider should be used
      # storageClass: storage-provider-name

tika:
  enabled: true

  gotenberg:
    global:
      nameOverride: gotenberg

    controllers:
      main:
        type: deployment
        strategy: RollingUpdate
        replicas: 1
        containers:
          main:
            image:
              repository: gotenberg/gotenberg
              tag: "8.24"
              pullPolicy: IfNotPresent
            command:
              - "gotenberg"
              - "--chromium-disable-javascript=true"
              - "--chromium-allow-list=file:///tmp/.*"
            ports:
              - name: http
                containerPort: 3000
                protocol: TCP
            # probes:
            #   liveness:
            #   readiness:
            #   startup:
            # ! set the following value as needed
            resources: {}

    service:
      main:
        enabled: true
        controller: main
        primary: true
        type: ClusterIP
        ports:
          http:
            enabled: true
            primary: true
            port: 3000
            targetPort: http
            protocol: HTTP

  tika:
    global:
      nameOverride: tika

    controllers:
      main:
        type: deployment
        strategy: RollingUpdate
        replicas: 1
        containers:
          main:
            image:
              repository: apache/tika
              tag: "3.2.3.0-full"
              pullPolicy: IfNotPresent
            ports:
              - name: http
                containerPort: 9998
                protocol: TCP
            # probes:
            #   liveness:
            #   readiness:
            #   startup:
            # ! set the following value as needed
            resources: {}

    service:
      main:
        enabled: true
        controller: main
        primary: true
        type: ClusterIP
        ports:
          http:
            enabled: true
            primary: true
            port: 9998
            targetPort: http
            protocol: HTTP
###
# ! the PostgreSQL cluster should be created using the [cnpg](https://cloudnative-pg.github.io/charts) cluster chart
# ! additionally to the cluster chart a secret for the cluster user is needed (not for this chart but for cnpg/cluster)
